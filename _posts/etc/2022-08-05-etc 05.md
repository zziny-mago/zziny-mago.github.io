---
layout: post
title:  "Invariance and Equivariance"
subtitle:   "python,데이터 사이언티스트, 인공지능 개발자를 위함"
categories: etc
tags: etc
comments: true
---

# Translational Equivariance
+ Translational Equivariance는 CNN에서 객체를 감지하기 위해 객체의 위치가 고정되지 않아도 되는 중요한 속성이다. 
+ 단순히 입력이 변경되면 출력도 변경되는것을 뜻한다. (여기서 변경은 회전변경이 아닌 이동이다) -> 입력 이미지 객체가 이동되면 변화를 감지하여 출력을 
# Translational Invariance
+ 입력의 위치가 변해도 함수의 출력의 결과가 유지되는 특성이다. 
+ 객체가 이미지 어디 위치에 있던 객체의 라벨 출력물에 영향을 끼치지 않는다는 것이다. 

## Equivariance한 특성이 Invariance것으로 바뀌는 과정
+ 파란색 이미지 하단 부분 코와 눈이 위치 
+ 눈 필터와 코 필터를 사용해서 만든 녹색채널은 하단부분에 큰 활성화 값을 가지게 출력
+ 더 깊은 레이에서는 녹색 채널 하단 눈과 코의 부분을 얼굴 필터를 사용해서 만든 얼굴 채널 하단부분 활성화 


![image](https://user-images.githubusercontent.com/70193130/183013576-9ee75fed-1975-4021-81db-8f7fb0e51988.png)

+ Equivariance한 특성때문에 상단 부분에 눈과 코가 있어서 출력결과물 채널에 상단에 활성화
+ 하지만 fc와 softmax함수를 거친 결과는 특징의 위치와는 상관없이 동등한 label의 결과값을 보여주기 때문에 Invariance하다. 

![image](https://user-images.githubusercontent.com/70193130/183013590-9e431c93-b1eb-4cdb-a1e2-bcad38109dd5.png)



# Permutation Equivariance
+ 밑에 이미지를 보면 6개의 노드가 있고 6! 만큼 순서의 가짓수가 나온다.  
+ 각 노드들의 순서가 바뀌어도 같은 position(그래프구조안에서)이 같으면 같은 feature vector를 같는다. 
![image](https://user-images.githubusercontent.com/70193130/183017466-bc3ffc79-25c5-4999-9113-e99a28dd9521.png)
# Permutation Invariance
+ Translational이 위치에 관한것이였다면 Graph에서 Permutation 즉 함수의 들어가는 노드들의 순서와 관련이 있다. 
+ Permutation Invariance는 인접행렬에 배치되는 노드들의 순서와 상관없이 동일한 함수의 출력결과물을 기대한다. 
![image](https://user-images.githubusercontent.com/70193130/183016775-e5965c54-ad52-4a12-b1ce-c0e92cee8489.png)


## Reference:  
<https://towardsdatascience.com/translational-invariance-vs-translational-equivariance-f9fbc8fca63a>
<https://process-mining.tistory.com/160>